{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f66966a8-6a26-4a2b-8937-43116df81c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasetup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9457061-9fb4-49dd-b6b2-52fa13e02a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mresnet50\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdensenet121\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mefficientnetb0\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/private/LeafClassification/LeafDisease_classifier/resnet50.py:43\u001b[0m\n\u001b[1;32m     40\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(class_counts\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m     41\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m\n\u001b[1;32m     42\u001b[0m weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[0;32m---> 43\u001b[0m     \u001b[43m[\u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclass_counts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     44\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat\n\u001b[1;32m     45\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     47\u001b[0m resnet_model \u001b[38;5;241m=\u001b[39m resnet_model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     48\u001b[0m criterion_res \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(weight\u001b[38;5;241m=\u001b[39mweights)\n",
      "File \u001b[0;32m~/private/LeafClassification/LeafDisease_classifier/resnet50.py:43\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     40\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(class_counts\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m     41\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m\n\u001b[1;32m     42\u001b[0m weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[0;32m---> 43\u001b[0m     [\u001b[43mtotal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclass_counts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_classes)],\n\u001b[1;32m     44\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat\n\u001b[1;32m     45\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     47\u001b[0m resnet_model \u001b[38;5;241m=\u001b[39m resnet_model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     48\u001b[0m criterion_res \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(weight\u001b[38;5;241m=\u001b[39mweights)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "from resnet50 import *\n",
    "from densenet121 import *\n",
    "from efficientnetb0 import *\n",
    "from mobilenetv2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4da1c2fa-4c95-49dc-891f-2357976dbe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a9bbedc-e21b-48d3-bfe8-8ec98c37828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_unfreeze(model, name, criterion, optimizer, dataloaders, num_epochs=10, patience=3, freeze_epochs=2):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    history = {\"train_loss\": [], \"train_acc\": [],\n",
    "               \"test_loss\": [], \"test_acc\": [], \"test_f1\": []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        # UNFREEZE after N epochs\n",
    "        if epoch == freeze_epochs:\n",
    "            print(\"Unfreezing backbone...\")\n",
    "            if name == \"ResNet50\":\n",
    "                for layer in [model.conv1, model.bn1, model.layer1, model.layer2, model.layer3, model.layer4]:\n",
    "                    for param in layer.parameters():\n",
    "                        param.requires_grad = True\n",
    "            else:\n",
    "                for param in model.features.parameters():  # or model.backbone if different\n",
    "                    param.requires_grad = True\n",
    "            optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "\n",
    "        for phase in [\"train\", \"test\"]:\n",
    "            model.train() if phase == \"train\" else model.eval()\n",
    "            running_loss, running_corrects = 0.0, 0\n",
    "            y_true, y_pred = [], []\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "                y_pred.extend(preds.cpu().numpy())\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.float() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            history[f\"{phase}_loss\"].append(epoch_loss)\n",
    "            history[f\"{phase}_acc\"].append(epoch_acc.item())\n",
    "\n",
    "            if phase == \"test\":\n",
    "                f1 = f1_score(y_true, y_pred)\n",
    "                history[\"test_f1\"].append(f1)\n",
    "\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    epochs_no_improve = 0\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "\n",
    "                if epochs_no_improve >= patience:\n",
    "                    print(\"Early stopping.\")\n",
    "                    model.load_state_dict(best_model_wts)\n",
    "                    return model, history, y_true, y_pred\n",
    "\n",
    "            print(f\"{phase} loss: {epoch_loss:.4f}, acc: {epoch_acc:.4f}\")\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history, y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91314a79-93a7-4902-883a-8a2f3f9287a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold(model_fn,name, dataset, weights, k=5, freeze_epochs=2, num_epochs=10, patience=3):\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    labels = [dataset.img_labels[i] for i in range(len(dataset))]\n",
    "\n",
    "    all_f1_curves = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(dataset, labels)):\n",
    "        print(f\"\\n======= Fold {fold+1}/{k} =======\")\n",
    "\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "        dataloaders_fold = {\n",
    "            \"train\": torch.utils.data.DataLoader(train_subset, batch_size=32, shuffle=True),\n",
    "            \"test\": torch.utils.data.DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "        }\n",
    "\n",
    "        model = model_fn().to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "        if name == \"ResNet50\":\n",
    "            optimizer = optimizer_res\n",
    "        else: optimizer = optim.Adam(model.classifier.parameters(), lr=1e-3)\n",
    "\n",
    "        model, history, _, _ = train_with_unfreeze(\n",
    "            model,name, criterion, optimizer, dataloaders_fold,\n",
    "            num_epochs=num_epochs, patience=patience,\n",
    "            freeze_epochs=freeze_epochs\n",
    "        )\n",
    "\n",
    "        all_f1_curves.append(history[\"test_f1\"])\n",
    "\n",
    "    return all_f1_curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06198e91-542c-4650-af38-82ccb62e0623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_avg_f1_across_folds(model_name, all_f1_curves):\n",
    "    avg_f1 = np.mean(np.array([np.pad(f, (0, max(map(len, all_f1_curves)) - len(f)), 'edge') for f in all_f1_curves]), axis=0)\n",
    "\n",
    "    plt.plot(range(1, len(avg_f1)+1), avg_f1, label=model_name)\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Avg F1 Score\")\n",
    "    plt.title(f\"F1 Curve Across Folds - {model_name}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d2e1ddb-7963-417b-baca-919db7d6fd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running K-Fold for ResNet50 ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models_info:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Running K-Fold for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m     all_f1_curves \u001b[38;5;241m=\u001b[39m run_k_fold(\n\u001b[1;32m     11\u001b[0m         model_fn\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     12\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m     13\u001b[0m         dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[0;32m---> 14\u001b[0m         weights\u001b[38;5;241m=\u001b[39m\u001b[43mweights\u001b[49m,\n\u001b[1;32m     15\u001b[0m         k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     16\u001b[0m         num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     17\u001b[0m         freeze_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m     plot_avg_f1_across_folds(name, all_f1_curves)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weights' is not defined"
     ]
    }
   ],
   "source": [
    "models_info = [\n",
    "    #(\"DenseNet121\", lambda: copy.deepcopy(densenet_model)),\n",
    "    #(\"MobileNetV2\", lambda: copy.deepcopy(mobilenet_model)),\n",
    "    #(\"EfficientNetB0\", lambda: copy.deepcopy(efficientnet_model)),\n",
    "    (\"ResNet50\", lambda: copy.deepcopy(resnet_model))\n",
    "]\n",
    "\n",
    "for name, model in models_info:\n",
    "    print(f\"\\n=== Running K-Fold for {name} ===\")\n",
    "    all_f1_curves = run_k_fold(\n",
    "        model_fn=model,\n",
    "        name=name,\n",
    "        dataset=dataset,\n",
    "        weights=weights,\n",
    "        k=5,\n",
    "        num_epochs=10,\n",
    "        freeze_epochs=2\n",
    "    )\n",
    "    plot_avg_f1_across_folds(name, all_f1_curves)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5e6ecc-a738-4547-9246-d1b825aa9a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
